{"issue_number": 393, "issue_title": "llama model list keeps fail in a fresh env: module 'jsonschema' has no attribute 'Draft201909Validator", "issue_body": "Create a new env and try to download llama3.2 model, but get following exceptions:\n`\n\nllama model list\nTraceback (most recent call last):\nFile \"/home/shijiexu/.local/bin/llama\", line 5, in \nfrom llama_stack.cli.llama import main\nFile \"/home/shijiexu/.local/lib/python3.10/site-packages/llama_stack/init.py\", line 7, in \nfrom llama_stack.distribution.library_client import (  # noqa: F401\nFile \"/home/shijiexu/.local/lib/python3.10/site-packages/llama_stack/distribution/library_client.py\", line 32, in \nfrom llama_stack.distribution.build import print_pip_install_help\nFile \"/home/shijiexu/.local/lib/python3.10/site-packages/llama_stack/distribution/build.py\", line 16, in \nfrom llama_stack.distribution.datatypes import BuildConfig, Provider\nFile \"/home/shijiexu/.local/lib/python3.10/site-packages/llama_stack/distribution/datatypes.py\", line 11, in \nfrom llama_stack.apis.benchmarks import Benchmark, BenchmarkInput\nFile \"/home/shijiexu/.local/lib/python3.10/site-packages/llama_stack/apis/benchmarks/init.py\", line 7, in \nfrom .benchmarks import *  # noqa: F401 F403\nFile \"/home/shijiexu/.local/lib/python3.10/site-packages/llama_stack/apis/benchmarks/benchmarks.py\", line 11, in \nfrom llama_stack.schema_utils import json_schema_type, webmethod\nFile \"/home/shijiexu/.local/lib/python3.10/site-packages/llama_stack/schema_utils.py\", line 10, in \nfrom .strong_typing.schema import json_schema_type, register_schema  # noqa: F401\nFile \"/home/shijiexu/.local/lib/python3.10/site-packages/llama_stack/strong_typing/schema.py\", line 616, in \nclass Validator(enum.Enum):\nFile \"/home/shijiexu/.local/lib/python3.10/site-packages/llama_stack/strong_typing/schema.py\", line 620, in Validator\nDraft201909 = jsonschema.Draft201909Validator\nAttributeError: module 'jsonschema' has no attribute 'Draft201909Validator'. Did you mean: 'Draft3Validator'?\n\n`\nAfter google, and most says it is jsonschema  package version issue. Therefore, I downgrade the version from 4.23.0 to 4.19.0, jsonschema-4.17.0, jsonschema 4.1.0, jsonschema-3.2.0.  But still the same error.\nAny tips?  thanks.", "created_at": "2025-03-22", "closed_at": null, "labels": [], "State": "open", "Author": "xushijie"}
{"issue_number": 392, "issue_title": "sp_model = SentencePieceProcessor()  sp_model.Load(\"/home/imss/zxhhhh/llama-3-8b/tokenizer.model\")", "issue_body": "when i run:\nsp_model = SentencePieceProcessor()\nsp_model.Load(\"/home/imss/zxhhhh/llama-3-8b/tokenizer.model\")\nit reported error:\nsp_model = SentencePieceProcessor()  sp_model.Load(\"/home/imss/zxhhhh/llama-3-8b/tokenizer.model\")\nwho can help me", "created_at": "2025-03-17", "closed_at": null, "labels": [], "State": "open", "Author": "ZhangXiaohan-TJU"}
{"issue_number": 388, "issue_title": "Which of these datasets were not utilized in Llama3.3-70B training?", "issue_body": "I am trying to find a dataset (or a set of clinical notes) that were not utilized during Llama3.3 (specifically 70B model) training. Which of the below datasets were not utilized in Llama3.3 training? Can anyone help please?\n\nMIMIC-III (Medical Information Mart for Intensive Care III)\ni2b2 (Informatics for Integrating Biology & the Bedside)\nn2c2 (National NLP Clinical Challenges)\nSHARE (Stanford Health AI Research and Evaluation)\nPhysioNet\nCLEF eHealth\nTREC Medical Records Track\nOpenNotes\neICU Collaborative Research Database\nPubMed Central (PMC) Open Access Subset\n\nThanks!", "created_at": "2025-03-10", "closed_at": null, "labels": [], "State": "open", "Author": "vthakkarumn"}
{"issue_number": 396, "issue_title": "Difficulty Accessing Llama-3.1, 3.2, 3.3, and Llama 4.", "issue_body": "I tried accessing the Llama Models through Hugging Face and all the models later than and including Llama 3.1 failed. I am getting an error saying that I don't have permission to access the repository. I tried accessing them on the Llama website and it also failed.", "created_at": "2025-04-08", "closed_at": null, "labels": [], "State": "open", "Author": "nrcoleman"}
{"issue_number": 395, "issue_title": "How to SFT llama3 with a labelled dataset", "issue_body": "Hi, there,\nWe want to SFT a llama3 model with a dataset, with following format,\n[\n   {\n      \"question\": \"the content of question 1 ...\", \n      \"answer\":  \"the content of answer 1 ...\", \n      \"label\":  either \"good\" or \"bad\", to evaluate the answer. \n   },\n   ...\n]\n\nOur questions are,\n\n\nHow to convert this dataset's format into the format that is acceptable by Llama3?\n\n\nOut of curiosity, what will happen inside Llama3 during training, if we convert the dateset into the following format?\n<|begin_of_text|>\n      <|start_header_id|>question<|end_header_id|>\n      Here is my first question ...\n\n      <|start_header_id|>answer<|end_header_id|>\n      Here is the LLM's answer to the first question ...\n\n      <|start_header_id|>system<|end_header_id|>\n      good\n   <|eot_id|>\n      ...\n<|end_of_text|>\n\nAs SFT, for each message, will Llama3 take the question as prompt, and start Llama3's prediction from answer?  If so, what will happen to eval that is either \"good\" or \"bad\"?\n\n\nMany thanks,\nKan", "created_at": "2025-03-29", "closed_at": null, "labels": [], "State": "open", "Author": "kandeng"}
